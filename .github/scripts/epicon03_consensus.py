#!/usr/bin/env python3
"""
EPICON-03 Multi-Agent Consensus Engine

Orchestrates multi-agent epistemic consensus for authority-bearing actions.
Implements the EPICON-03 specification for collective epistemic verification.

Reference: docs/epicon/EPICON-03.md
"""

import hashlib
import json
import os
import sys
import uuid
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
from typing import Optional


class Stance(Enum):
    SUPPORT = "support"
    CONDITIONAL = "conditional"
    OPPOSE = "oppose"


class ConsensusStatus(Enum):
    PASS = "pass"
    NEEDS_CLARIFICATION = "needs_clarification"
    FAIL = "fail"


@dataclass
class AgentReport:
    """Individual agent evaluation report."""
    agent_id: str
    provider: str
    model: str
    stance: Stance
    confidence: float
    ej_hash: str
    ccr_score: float = 0.0
    anchor_count: int = 0
    anchor_types: list[str] = field(default_factory=list)
    reasoning_summary: str = ""
    conditions: list[str] = field(default_factory=list)
    objections: list[str] = field(default_factory=list)
    questions: list[str] = field(default_factory=list)
    generated_at: str = ""
    
    def __post_init__(self):
        if not self.generated_at:
            self.generated_at = datetime.now(timezone.utc).isoformat()


@dataclass
class ConsensusRequest:
    """Request for multi-agent consensus."""
    request_id: str
    repo: str
    action: str
    scope: list[str]
    changed_files: list[str]
    agents_required: int = 5
    pr: Optional[int] = None
    intent_hash: Optional[str] = None
    thresholds: dict = field(default_factory=lambda: {
        "pass_ecs": 0.75,
        "clarify_ecs": 0.55,
        "min_agents": 3,
        "agreement_ratio": 0.67
    })
    context: dict = field(default_factory=dict)
    requested_at: str = ""
    
    def __post_init__(self):
        if not self.request_id:
            self.request_id = str(uuid.uuid4())
        if not self.requested_at:
            self.requested_at = datetime.now(timezone.utc).isoformat()


@dataclass
class Conflict:
    """Conflict between agent evaluations."""
    claim: str
    agents: list[str]
    resolution: str = ""
    severity: str = "medium"


@dataclass
class ConsensusAttestation:
    """Multi-agent consensus attestation."""
    version: str = "EPICON-03"
    request_id: str = ""
    generated_at: str = ""
    status: ConsensusStatus = ConsensusStatus.FAIL
    ecs: float = 0.0
    ecs_components: dict = field(default_factory=dict)
    quorum: dict = field(default_factory=dict)
    vote: dict = field(default_factory=lambda: {
        "support": 0,
        "conditional": 0,
        "oppose": 0
    })
    conflicts: list[Conflict] = field(default_factory=list)
    required_questions: list[str] = field(default_factory=list)
    css_status: dict = field(default_factory=lambda: {"all_pass": True, "violations": []})
    agent_reports: list[AgentReport] = field(default_factory=list)
    dissent_bundle: Optional[dict] = None
    attestation: dict = field(default_factory=dict)
    metadata: dict = field(default_factory=dict)
    
    def __post_init__(self):
        if not self.generated_at:
            self.generated_at = datetime.now(timezone.utc).isoformat()


class ConsensusEngine:
    """
    Multi-Agent Consensus Engine for EPICON-03.
    
    Orchestrates agent evaluation, computes consensus scores,
    and generates attestations.
    """
    
    # ECS score weights
    W_AGREEMENT = 0.40
    W_ANCHOR_DIVERSITY = 0.25
    W_CCR_ROBUSTNESS = 0.25
    W_CONFLICT_PENALTY = 0.10
    
    # Agent roster for MVP (simulated agents)
    AGENT_ROSTER = [
        {"agent_id": "aurea", "provider": "openai", "model": "gpt-4o", "role": "coverage"},
        {"agent_id": "atlas", "provider": "anthropic", "model": "claude-opus-4", "role": "integrity"},
        {"agent_id": "eve", "provider": "anthropic", "model": "claude-sonnet-4", "role": "edge_cases"},
        {"agent_id": "hermes", "provider": "google", "model": "gemini-pro", "role": "cross_reference"},
        {"agent_id": "jade", "provider": "local", "model": "ollama/llama", "role": "privacy"},
    ]
    
    def __init__(self, request: ConsensusRequest):
        self.request = request
        self.agent_reports: list[AgentReport] = []
        self.conflicts: list[Conflict] = []
    
    def run_consensus(self) -> ConsensusAttestation:
        """
        Run the full consensus process.
        
        Returns:
            ConsensusAttestation with the result
        """
        start_time = datetime.now(timezone.utc)
        
        # 1. Dispatch to agents (MVP: simulated)
        self.agent_reports = self._dispatch_agents()
        
        # 2. Verify quorum
        quorum = self._verify_quorum()
        
        # 3. Tally votes
        vote = self._tally_votes()
        
        # 4. Detect conflicts
        self.conflicts = self._detect_conflicts()
        
        # 5. Compute ECS
        ecs, ecs_components = self._compute_ecs()
        
        # 6. Determine status
        status = self._determine_status(ecs, vote, quorum)
        
        # 7. Collect required questions
        required_questions = self._collect_questions()
        
        # 8. Build dissent bundle if needed
        dissent_bundle = self._build_dissent_bundle(vote)
        
        # 9. Generate attestation
        attestation_sig = self._generate_attestation()
        
        end_time = datetime.now(timezone.utc)
        duration_ms = int((end_time - start_time).total_seconds() * 1000)
        
        return ConsensusAttestation(
            request_id=self.request.request_id,
            status=status,
            ecs=ecs,
            ecs_components=ecs_components,
            quorum=quorum,
            vote=vote,
            conflicts=self.conflicts,
            required_questions=required_questions,
            css_status=self._check_css_status(),
            agent_reports=self.agent_reports,
            dissent_bundle=dissent_bundle,
            attestation=attestation_sig,
            metadata={
                "duration_ms": duration_ms,
                "retry_count": 0,
                "partial": len(self.agent_reports) < self.request.agents_required
            }
        )
    
    def _dispatch_agents(self) -> list[AgentReport]:
        """
        Dispatch evaluation to agents.
        
        MVP: Returns simulated agent reports.
        Production: Would call actual AI providers.
        """
        reports = []
        
        # For MVP, simulate agent responses based on request context
        for i, agent_config in enumerate(self.AGENT_ROSTER[:self.request.agents_required]):
            report = self._simulate_agent_evaluation(agent_config)
            reports.append(report)
        
        return reports
    
    def _simulate_agent_evaluation(self, agent_config: dict) -> AgentReport:
        """
        Simulate an agent evaluation (MVP).
        
        In production, this would:
        1. Call the actual AI provider API
        2. Parse the response into EPICON-01 EJ format
        3. Extract stance and confidence
        """
        import random
        
        # Simulate varied responses based on scope
        is_governance = "governance" in self.request.scope or "code_ownership" in self.request.scope
        is_specs = "specs" in self.request.scope
        is_docs = "docs" in self.request.scope
        is_ci_only = self.request.scope == ["ci"] or (
            len(self.request.scope) == 1 and "ci" in self.request.scope
        )
        is_docs_only = self.request.scope == ["docs"] or (
            len(self.request.scope) == 1 and "docs" in self.request.scope
        )
        
        # Governance changes get most scrutiny
        if is_governance:
            stance_weights = [0.5, 0.35, 0.15]  # More conditionals/opposes
            base_confidence = 0.70
        # Specs without governance get moderate scrutiny
        elif is_specs and not is_docs_only:
            stance_weights = [0.65, 0.25, 0.10]  # Moderate scrutiny
            base_confidence = 0.75
        # CI-only or docs-only changes are lower risk
        elif is_ci_only or is_docs_only:
            stance_weights = [0.85, 0.12, 0.03]  # Mostly supports
            base_confidence = 0.85
        # Docs mixed with other scopes
        elif is_docs:
            stance_weights = [0.80, 0.15, 0.05]  # Lenient
            base_confidence = 0.82
        else:
            stance_weights = [0.75, 0.20, 0.05]  # More supports
            base_confidence = 0.80
        
        # Randomize with weights
        stance_roll = random.random()
        if stance_roll < stance_weights[0]:
            stance = Stance.SUPPORT
        elif stance_roll < stance_weights[0] + stance_weights[1]:
            stance = Stance.CONDITIONAL
        else:
            stance = Stance.OPPOSE
        
        # Generate confidence with some variance
        confidence = min(1.0, max(0.0, base_confidence + random.uniform(-0.15, 0.15)))
        
        # Generate fake EJ hash
        ej_content = json.dumps({
            "agent": agent_config["agent_id"],
            "scope": self.request.scope,
            "timestamp": datetime.now(timezone.utc).isoformat()
        })
        ej_hash = f"sha256:{hashlib.sha256(ej_content.encode()).hexdigest()}"
        
        # Generate conditions/objections based on stance
        conditions = []
        objections = []
        questions = []
        
        if stance == Stance.CONDITIONAL:
            conditions = [
                "Ensure all required fields are present in intent publication",
                "Verify scope alignment with changed files"
            ]
            questions = ["Please clarify the justification for this authority change."]
        elif stance == Stance.OPPOSE:
            objections = [
                "Intent publication missing critical fields",
                "Scope exceeds declared authority"
            ]
        
        # Anchor types
        anchor_types = ["policy", "practice"]
        if agent_config["role"] == "coverage":
            anchor_types.append("empirical")
        if agent_config["role"] == "edge_cases":
            anchor_types.append("domain_norm")
        
        return AgentReport(
            agent_id=agent_config["agent_id"],
            provider=agent_config["provider"],
            model=agent_config["model"],
            stance=stance,
            confidence=round(confidence, 2),
            ej_hash=ej_hash,
            ccr_score=round(random.uniform(0.6, 0.95), 2),
            anchor_count=len(anchor_types),
            anchor_types=anchor_types,
            reasoning_summary=f"Evaluated PR for {', '.join(self.request.scope)} scope.",
            conditions=conditions,
            objections=objections,
            questions=questions
        )
    
    def _verify_quorum(self) -> dict:
        """Verify quorum requirements are met."""
        agents_responded = len(self.agent_reports)
        min_required = self.request.thresholds.get("min_agents", 3)
        
        # Check provider diversity for independence
        providers = set(r.provider for r in self.agent_reports)
        independent_ok = len(providers) >= 2
        
        return {
            "agents": agents_responded,
            "min_required": min_required,
            "independent_ok": independent_ok,
            "providers": list(providers)
        }
    
    def _tally_votes(self) -> dict:
        """Tally votes from agent reports."""
        vote = {"support": 0, "conditional": 0, "oppose": 0}
        
        for report in self.agent_reports:
            if report.stance == Stance.SUPPORT:
                vote["support"] += 1
            elif report.stance == Stance.CONDITIONAL:
                vote["conditional"] += 1
            else:
                vote["oppose"] += 1
        
        return vote
    
    def _detect_conflicts(self) -> list[Conflict]:
        """Detect conflicts between agent evaluations."""
        conflicts = []
        
        # Check for stance conflicts
        stances = [r.stance for r in self.agent_reports]
        if Stance.SUPPORT in stances and Stance.OPPOSE in stances:
            supporters = [r.agent_id for r in self.agent_reports if r.stance == Stance.SUPPORT]
            opposers = [r.agent_id for r in self.agent_reports if r.stance == Stance.OPPOSE]
            conflicts.append(Conflict(
                claim="Agents disagree on action validity",
                agents=supporters + opposers,
                resolution="Review objections and address concerns",
                severity="high"
            ))
        
        # Check for condition conflicts
        all_conditions = []
        for r in self.agent_reports:
            if r.conditions:
                all_conditions.extend([(r.agent_id, c) for c in r.conditions])
        
        if len(all_conditions) > 2:
            agents_with_conditions = list(set(a for a, _ in all_conditions))
            conflicts.append(Conflict(
                claim="Multiple agents require conditions",
                agents=agents_with_conditions,
                resolution="Address all conditions before proceeding",
                severity="medium"
            ))
        
        return conflicts
    
    def _compute_ecs(self) -> tuple[float, dict]:
        """
        Compute Epistemic Consensus Score.
        
        ECS = w1*Agreement + w2*AnchorDiversity + w3*CCR_Robustness - w4*ConflictPenalty
        """
        n = len(self.agent_reports)
        if n == 0:
            return 0.0, {}
        
        # Agreement = Support / N
        vote = self._tally_votes()
        agreement = vote["support"] / n
        
        # Anchor Diversity = unique anchor types / max possible
        all_anchor_types = set()
        for r in self.agent_reports:
            all_anchor_types.update(r.anchor_types)
        anchor_diversity = min(1.0, len(all_anchor_types) / 6)  # 6 possible types
        
        # CCR Robustness = min CCR across agents
        ccr_scores = [r.ccr_score for r in self.agent_reports]
        ccr_robustness = min(ccr_scores) if ccr_scores else 0.0
        
        # Conflict Penalty = conflicts / max expected
        conflict_penalty = min(1.0, len(self.conflicts) / 3)
        
        # Compute ECS
        ecs = (
            self.W_AGREEMENT * agreement +
            self.W_ANCHOR_DIVERSITY * anchor_diversity +
            self.W_CCR_ROBUSTNESS * ccr_robustness -
            self.W_CONFLICT_PENALTY * conflict_penalty
        )
        
        ecs = max(0.0, min(1.0, ecs))
        
        components = {
            "agreement": round(agreement, 3),
            "anchor_diversity": round(anchor_diversity, 3),
            "ccr_robustness": round(ccr_robustness, 3),
            "conflict_penalty": round(conflict_penalty, 3)
        }
        
        return round(ecs, 3), components
    
    def _determine_status(
        self,
        ecs: float,
        vote: dict,
        quorum: dict
    ) -> ConsensusStatus:
        """Determine consensus status based on ECS and votes."""
        pass_threshold = self.request.thresholds.get("pass_ecs", 0.75)
        clarify_threshold = self.request.thresholds.get("clarify_ecs", 0.55)
        agreement_ratio = self.request.thresholds.get("agreement_ratio", 0.67)
        
        n = len(self.agent_reports)
        
        # Check for any CSS violations
        css = self._check_css_status()
        if not css["all_pass"]:
            return ConsensusStatus.FAIL
        
        # Check quorum
        if not quorum["independent_ok"]:
            return ConsensusStatus.FAIL
        
        if quorum["agents"] < quorum["min_required"]:
            return ConsensusStatus.FAIL
        
        # Check for any opposition
        if vote["oppose"] > 0:
            return ConsensusStatus.FAIL
        
        # Check ECS threshold
        if ecs < clarify_threshold:
            return ConsensusStatus.FAIL
        
        # Check agreement ratio
        if n > 0 and (vote["support"] / n) < agreement_ratio:
            return ConsensusStatus.NEEDS_CLARIFICATION
        
        # Check for conditional votes
        if vote["conditional"] > 0:
            return ConsensusStatus.NEEDS_CLARIFICATION
        
        if ecs >= pass_threshold:
            return ConsensusStatus.PASS
        
        return ConsensusStatus.NEEDS_CLARIFICATION
    
    def _check_css_status(self) -> dict:
        """Check Common-Sense Safety status across all agents."""
        # MVP: Assume CSS passes for all agents
        # Production: Would check actual CSS status from each EJ
        return {
            "all_pass": True,
            "violations": []
        }
    
    def _collect_questions(self) -> list[str]:
        """Collect clarifying questions from agents."""
        questions = []
        for r in self.agent_reports:
            questions.extend(r.questions)
        return list(set(questions))
    
    def _build_dissent_bundle(self, vote: dict) -> Optional[dict]:
        """Build dissent bundle if any agents opposed."""
        if vote["oppose"] == 0:
            return None
        
        dissenters = [r.agent_id for r in self.agent_reports if r.stance == Stance.OPPOSE]
        claims = []
        questions = []
        
        for r in self.agent_reports:
            if r.stance == Stance.OPPOSE:
                claims.extend(r.objections)
                questions.extend(r.questions)
        
        return {
            "dissenters": dissenters,
            "claims": list(set(claims)),
            "questions": list(set(questions))
        }
    
    def _generate_attestation(self) -> dict:
        """Generate cryptographic attestation."""
        # Build merkle root from agent reports
        report_hashes = [r.ej_hash for r in self.agent_reports]
        combined = "".join(sorted(report_hashes))
        merkle_root = f"sha256:{hashlib.sha256(combined.encode()).hexdigest()}"
        
        return {
            "merkle_root": merkle_root,
            "signers": ["mobius-bot-key"],
            "signature": "ed25519:<signature-placeholder>"
        }
    
    def to_json(self, attestation: ConsensusAttestation) -> str:
        """Convert attestation to JSON string."""
        def serialize(obj):
            if isinstance(obj, Enum):
                return obj.value
            if isinstance(obj, (Conflict, AgentReport)):
                return {k: serialize(v) for k, v in obj.__dict__.items()}
            if isinstance(obj, list):
                return [serialize(i) for i in obj]
            if isinstance(obj, dict):
                return {k: serialize(v) for k, v in obj.items()}
            return obj
        
        data = {
            "version": attestation.version,
            "request_id": attestation.request_id,
            "generated_at": attestation.generated_at,
            "status": attestation.status.value,
            "ecs": attestation.ecs,
            "ecs_components": attestation.ecs_components,
            "quorum": attestation.quorum,
            "vote": attestation.vote,
            "conflicts": serialize(attestation.conflicts),
            "required_questions": attestation.required_questions,
            "css_status": attestation.css_status,
            "agent_reports": serialize(attestation.agent_reports),
            "dissent_bundle": attestation.dissent_bundle,
            "attestation": attestation.attestation,
            "metadata": attestation.metadata
        }
        
        return json.dumps(data, indent=2)


def generate_pr_comment(attestation: ConsensusAttestation) -> str:
    """Generate a PR comment from the consensus attestation."""
    status_emoji = {
        ConsensusStatus.PASS: "‚úÖ",
        ConsensusStatus.NEEDS_CLARIFICATION: "‚ö†Ô∏è",
        ConsensusStatus.FAIL: "‚ùå"
    }[attestation.status]
    
    lines = [
        f"## üåÄ Mobius EPICON-03 Consensus: {status_emoji} {attestation.status.value.upper()}",
        "",
        "### Consensus Summary",
        "",
        f"| Metric | Value |",
        f"|--------|-------|",
        f"| **ECS Score** | {attestation.ecs:.2f} |",
        f"| **Agents** | {attestation.quorum.get('agents', 0)} / {attestation.quorum.get('min_required', 0)} |",
        f"| **Vote** | Support: {attestation.vote['support']}, Conditional: {attestation.vote['conditional']}, Oppose: {attestation.vote['oppose']} |",
        f"| **Independence** | {'‚úÖ' if attestation.quorum.get('independent_ok') else '‚ùå'} |",
        "",
    ]
    
    # Add ECS components
    if attestation.ecs_components:
        lines.extend([
            "### ECS Breakdown",
            "",
            "| Component | Score |",
            "|-----------|-------|",
            f"| Agreement | {attestation.ecs_components.get('agreement', 0):.2f} |",
            f"| Anchor Diversity | {attestation.ecs_components.get('anchor_diversity', 0):.2f} |",
            f"| CCR Robustness | {attestation.ecs_components.get('ccr_robustness', 0):.2f} |",
            f"| Conflict Penalty | -{attestation.ecs_components.get('conflict_penalty', 0):.2f} |",
            "",
        ])
    
    # Add agent reports summary
    lines.extend([
        "### Agent Reports",
        "",
        "| Agent | Provider | Stance | Confidence |",
        "|-------|----------|--------|------------|",
    ])
    
    for r in attestation.agent_reports:
        stance_emoji = {"support": "üëç", "conditional": "ü§î", "oppose": "üëé"}
        stance_str = f"{stance_emoji.get(r.stance.value, '‚ùì')} {r.stance.value}"
        lines.append(f"| {r.agent_id} | {r.provider} | {stance_str} | {r.confidence:.0%} |")
    
    lines.append("")
    
    # Add conflicts if any
    if attestation.conflicts:
        lines.extend([
            "### Conflicts Detected",
            "",
        ])
        for c in attestation.conflicts:
            lines.append(f"- **{c.claim}** (Agents: {', '.join(c.agents)})")
            if c.resolution:
                lines.append(f"  - Resolution: {c.resolution}")
        lines.append("")
    
    # Add required questions if any
    if attestation.required_questions:
        lines.extend([
            "### Required Clarifications",
            "",
        ])
        for q in attestation.required_questions:
            lines.append(f"- {q}")
        lines.append("")
    
    # Add dissent bundle if any
    if attestation.dissent_bundle:
        lines.extend([
            "### Dissent Bundle",
            "",
            f"**Dissenters:** {', '.join(attestation.dissent_bundle['dissenters'])}",
            "",
            "**Claims:**",
            "",
        ])
        for claim in attestation.dissent_bundle.get("claims", []):
            lines.append(f"- {claim}")
        lines.append("")
    
    lines.extend([
        "---",
        "",
        f"*Generated at: {attestation.generated_at}*  ",
        f"*Request ID: {attestation.request_id}*",
        "",
        "*[EPICON-03 Reference](../docs/epicon/EPICON-03.md)*",
    ])
    
    return "\n".join(lines)


def main():
    """CLI entry point."""
    # Example usage
    request = ConsensusRequest(
        request_id=str(uuid.uuid4()),
        repo="kaizencycle/Mobius-Systems",
        pr=215,
        action="merge",
        scope=["governance", "code_ownership"],
        changed_files=[".github/CODEOWNERS", ".github/PULL_REQUEST_TEMPLATE.md"],
        agents_required=5
    )
    
    engine = ConsensusEngine(request)
    attestation = engine.run_consensus()
    
    print("=== Consensus Attestation (JSON) ===")
    print(engine.to_json(attestation))
    print()
    
    print("=== PR Comment ===")
    print(generate_pr_comment(attestation))


if __name__ == "__main__":
    main()
